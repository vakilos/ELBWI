{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Run this notebook in the qiime2 conda installation environoment and add the Biopython module \n",
    "\n",
    "import re,os, subprocess\n",
    "import pandas as pd\n",
    "import qiime2\n",
    "import glob\n",
    "from qiime2 import Metadata\n",
    "from qiime2.plugins import feature_table\n",
    "import qiime2.plugins.dada2.actions as dada2\n",
    "from qiime2.plugins.vsearch.methods import uchime_denovo\n",
    "from qiime2.plugins.feature_table.methods import filter_features\n",
    "from qiime2.plugins.feature_classifier.methods import classify_sklearn\n",
    "\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import itertools\n",
    "\n",
    "\n",
    "def create_manifest(directory):\n",
    "    files = [directory+'/'+file for file in os.listdir(directory) if file.endswith('.fastq.gz')]\n",
    "    os.chdir(directory)\n",
    "    with open('manifest.txt', 'w') as mani:\n",
    "        mani.write('sample-id,absolute-filepath,direction\\n')\n",
    "        for file in files:\n",
    "            sampleID =  re.match(re.compile(r'(\\w+)_R\\d\\.fastq\\.gz'), os.path.basename(file)).group(1)\n",
    "            direction = re.match(re.compile(r'\\w+_R(\\d)\\.fastq\\.gz'), os.path.basename(file)).group(1)\n",
    "            if direction == \"1\":\n",
    "                direction = 'forward'\n",
    "            else:\n",
    "                direction = 'reverse'\n",
    "\n",
    "            mani.write(sampleID+','+file+','+direction+'\\n')\n",
    "    mani.close()\n",
    "    \n",
    "def merge_complementary_asv(Fasta, CountsDf, Tag):\n",
    "    \"\"\"Creates a new fasta and a new asv_table that are dereplicated\"\"\"\n",
    "    #CountsDf  = CountsDf.copy()\n",
    "    FastaRec = list(SeqIO.parse(open(Fasta,'r'),'fasta'))\n",
    "    pairCount = 0\n",
    "    for rec1, rec2 in itertools.combinations(FastaRec, 2):\n",
    "        Seq1 = str(rec1.seq.reverse_complement())\n",
    "        if Seq1 == str(rec2.seq) or rec1.seq == rec2.seq:\n",
    "            pairCount += 1\n",
    "            CountsDf[rec1.id] = CountsDf[rec1.id] + CountsDf[rec2.id] ## arbitarily keep the first in the pair\n",
    "            CountsDf.drop(columns=[rec2.id], inplace=True) ## after the complementary ASVs are merged, remove the second of them from the table.\n",
    "    with open(\"asv_seqs.fasta\", 'w') as out:\n",
    "        NewFasta = [rec for rec in FastaRec if rec.id in CountsDf.columns]\n",
    "        SeqIO.write(NewFasta, out, 'fasta')\n",
    "    CountsDf.to_csv('final_asv_table.tsv', sep='\\t', index_label='SampleID')                                                   \n",
    "    print(\"{} ASVs were merged.\".format(pairCount)) \n",
    "    print(\"Exporting final_asv_table.tsv!\")\n",
    "    print('Exporting '+Tag+'_drep_dna-sequences.fasta')\n",
    "    out.close()\n",
    "    return CountsDf\n",
    "\n",
    "def parse_qiime2_taxonomy(TaxFile):\n",
    "    Tax = pd.read_csv(TaxFile, sep='\\t', index_col='Feature ID')\n",
    "    TaxDf = pd.DataFrame()\n",
    "    columns = [\"domain\", \"phylum\", \"class\", \"order\", 'family', 'genus', 'species', 'full', 'confidence']\n",
    "\n",
    "    for index, row in Tax.iterrows():\n",
    "        SplitTaxonomy = re.findall(r'__(\\w+);*', row[0])\n",
    "        while len(SplitTaxonomy) < 7:\n",
    "            SplitTaxonomy.append('Unassigned')\n",
    "        TaxDf = TaxDf.append(pd.DataFrame(dict(zip(columns, SplitTaxonomy+[row['Taxon'], row['Confidence']])), index=[index], columns=columns))\n",
    "\n",
    "    TaxDf = TaxDf.assign(asv=['ASV_'+str(i) for i in range(1,TaxDf.shape[0]+1)])\n",
    "    TaxDf = TaxDf.assign(ASVg=TaxDf[['asv','genus']].apply(lambda x:':'.join(x), axis=1))\n",
    "    TaxDf.reset_index(inplace=True)\n",
    "    TaxDf.rename(columns={'index':'asvid'}, inplace=True)\n",
    "    return TaxDf\n",
    "\n",
    "\n",
    "## Directory with the concatenated fastq files..\n",
    "myDir = '/media/christos/ssd/work/Infants/publication/sequence_data'\n",
    "\n",
    "### Root directory to be used for the project..\n",
    "rootDir = ''\n",
    "\n",
    "### all files exported from this notebook can be found here! \n",
    "exportDir = rootDir+'qiime2_dada2'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import files in qiime2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_manifest(myDir)\n",
    "manifesto = myDir+'/manifest.txt'\n",
    "\n",
    "### Parse files to qiime2\n",
    "demultiplexed_fastqs = qiime2.Artifact.import_data('SampleData[PairedEndSequencesWithQuality]', manifesto, view_type='PairedEndFastqManifestPhred33')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run DADA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running external command line application(s). This may print messages to stdout and/or stderr.\n",
      "The command(s) being run are below. These commands cannot be manually re-run as they will depend on temporary files that no longer exist.\n",
      "\n",
      "Command: run_dada_paired.R /tmp/tmpw34n7fqm/forward /tmp/tmpw34n7fqm/reverse /tmp/tmpw34n7fqm/output.tsv.biom /tmp/tmpw34n7fqm/track.tsv /tmp/tmpw34n7fqm/filt_f /tmp/tmpw34n7fqm/filt_r 230 230 0 0 20.0 2 consensus 1.0 3 1000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "asv_table, repr_seqs, denoising_stasts  = dada2.denoise_paired(demultiplexed_seqs=demultiplexed_fastqs,\n",
    "                                                               trunc_len_f=230, trunc_len_r=230,\n",
    "                                                               max_ee=20.0, n_threads=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(exportDir)\n",
    "asv_df = asv_table.view(pd.DataFrame)\n",
    "stats_df = denoising_stasts.view(Metadata).to_dataframe()\n",
    "total_reads = asv_df.sum(axis=1).to_frame().rename(columns={0:\"Total\"})\n",
    "stats_df.to_csv('ReadStats.csv') ## export read stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove chimeras with the vsearch uchime_denovo method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running external command line application. This may print messages to stdout and/or stderr.\n",
      "The command being run is below. This command cannot be manually re-run as it will depend on temporary files that no longer exist.\n",
      "\n",
      "Command: vsearch --uchime_denovo /tmp/tmpnl40uzqd --uchimeout /tmp/q2-UchimeStatsFmt-xfj0asai --nonchimeras /tmp/q2-DNAFASTAFormat-tv6i66cc --chimeras /tmp/tmpjl8tdyde --dn 1.4 --mindiffs 3 --mindiv 0.8 --minh 0.28 --xn 8.0 --qmask none --xsize\n",
      "\n",
      "287 ASVs detected.\n"
     ]
    }
   ],
   "source": [
    "### check and remove chimeras - uses dada2 output \n",
    "chimeras, non_chimeras, stats = uchime_denovo(sequences=repr_seqs, table=asv_table)\n",
    "#non_chimeras.save(tag+'_non_chimeras.qza')\n",
    "non_chimeras_df = non_chimeras.view(Metadata).to_dataframe() ### convert fasta Artifatct to dataframe\n",
    "asv_df = asv_table.view(pd.DataFrame).loc[:,non_chimeras_df.index] ## filter asv table for non-chimeric seqeuences\n",
    "repr_seqs_df = repr_seqs.view(Metadata).to_dataframe().loc[non_chimeras_df.index,:]## filter fasta file for non-chimeric sequences\n",
    "print('{} ASVs detected.'.format(asv_df.shape[1]))\n",
    "## write fasta record with non-chimeric sequences (to be used downstream for reverse complement dereplication)\n",
    "with open('preterm_nochimera_seqs.fasta', 'w') as out:\n",
    "    for index, row in repr_seqs_df.iterrows():\n",
    "        record = SeqRecord(Seq(row['Sequence']), id=index, description=index)\n",
    "        SeqIO.write(record, out, 'fasta')\n",
    "out.close() \n",
    "\n",
    "#### update the Readstats.csv \n",
    "stats = pd.read_csv('ReadStats.csv')\n",
    "tmp = asv_df.sum(axis=1).to_frame().rename(columns={0:\"After vsearch uchime\"}).reset_index().rename(columns={'index':'sample-id'})\n",
    "stats.merge(tmp, on='sample-id', how='inner').to_csv('ReadStats.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dereplicate reverse complement ASVs\n",
    "This section is the final processing step for the count table in the qiime2 pipeline. ***final_asv_table.tsv*** and ***asv_seqs.fasta*** exported files can be further used for downstream analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 ASVs were merged.\n",
      "Exporting final_asv_table.tsv!\n",
      "Exporting preterm_drep_dna-sequences.fasta\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/media/christos/ssd/work/Infants/publication/qiime2_dada2/asv_seqs.qza'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasta_file = 'preterm_nochimera_seqs.fasta'\n",
    "\n",
    "## This function will dereplicate the table and the respective file for reverse-complementary sequences \n",
    "asv_df = merge_complementary_asv(fasta_file, asv_df, Tag='preterm')\n",
    "\n",
    "#### update the Readstats.csv \n",
    "stats = pd.read_csv('ReadStats.csv')\n",
    "tmp = asv_df.sum(axis=1).to_frame().rename(columns={0:\"After rev_com_derep\"}).reset_index().rename(columns={'index':'sample-id'})\n",
    "stats.merge(tmp, on='sample-id', how='inner').to_csv('ReadStats.csv', index=False)\n",
    "\n",
    "query = qiime2.Artifact.import_data('FeatureData[Sequence]',exportDir+'/asv_seqs.fasta')\n",
    "query.save(exportDir+'/asv_seqs.qza')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taxonomic classification \n",
    "A classifier is trained for the region amplified by the primer pair 341F-785R using SILVA SSU 16S release 132 - check *trainFeatureClassifier.py* script). Keep in mind that ASV sequences derived from both DNA strands. Therefore, assign taxonomies for all ASVs for both  DNA strands. Exports ***taxonomy_table.tsv*** and ***final_asv_seqs.fasta*** . (Train the classifier and make the classification on a system with > 20GB of RAM. Then extract taxonomy folders and rename accordingly the taxonomy files to *taxonomy_f.tsv* and *taxonomy_r.tsv* respectively ) \n",
    "\n",
    "\n",
    "##### Train the classifier\n",
    "qiime feature-classifier fit-classifier-naive-bayes --i-reference-reads ref-reads.qza --i-reference-taxonomy ref-taxonomy.qza --o-classifier 16S-silva-341f-785r-classifier.qza --p-classify--chunk-size 20000\n",
    "\n",
    "##### Assign taxonomies forward\n",
    "qiime feature-classifier classify-sklearn --i-classifier 16S-silva-341f-785r-classifier.qza --i-reads asv_seqs.qza --o-classification taxonomy_f.qza\n",
    "\n",
    "##### Assign taxonomies reverse complement\n",
    "qiime feature-classifier classify-sklearn --p-read-orientation reverse-complement --i-classifier 16S-silva-341f-785r-classifier.qza --i-reads asv_seqs.qza --o-classification taxonomy_r.qza\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge forward and reverse taxonomic assignments \n",
    "os.chdir(exportDir)\n",
    "\n",
    "tax1 = 'taxonomy_f.tsv'\n",
    "tax2 = 'taxonomy_r.tsv'\n",
    "\n",
    "tax1_df  = parse_qiime2_taxonomy(tax1)\n",
    "tax1_df['strand'] = ['f' for  i in tax1_df.index]\n",
    "tax2_df = parse_qiime2_taxonomy(tax2)\n",
    "tax2_df['strand'] =['r' for i in tax2_df.index]\n",
    "\n",
    "tax_df = tax1_df.append(tax2_df, ignore_index=True)\n",
    "tax_df['badscore'] = tax_df.apply(lambda row: sum(row[0:tax_df.shape[1]]==\"Unassigned\"), axis=1)\n",
    "tax_df = tax_df.sort_values(['asvid','badscore'], ascending=True)\n",
    "tax_df.drop_duplicates(\"asvid\", inplace=True)\n",
    "otuIDs = tax_df['asvid']\n",
    "\n",
    "\"\"\"Check the orientation and then reverse complement the sequences in the FASTA. (should be asv_seqs.fasta)\"\"\"\n",
    "RC_otus = tax_df.loc[tax_df['strand'] == 'r']['asvid'].tolist()\n",
    "#tax_df.set_index('asvid',inplace=True)\n",
    "with open(\"asv_seqs.fasta\",'r') as old, open('final_asv_seqs.fasta','w') as new:\n",
    "    for record in SeqIO.parse(old,'fasta'):\n",
    "        if record.id in RC_otus:\n",
    "            record.seq = record.seq.reverse_complement()\n",
    "        SeqIO.write(record, new, 'fasta')\n",
    "old.close(), new.close()\n",
    "tax_df.drop(columns=['strand'], inplace=True)\n",
    "tax_df.to_csv('taxonomy_table.tsv', index=None, sep='\\t')\n",
    "\n",
    "#qtax_df.to_csv('/media/christos/ssd/work/Infants/qiime2/final-fulltaxonomy-table.tsv',index=None, sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
